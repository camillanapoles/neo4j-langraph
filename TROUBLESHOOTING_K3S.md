# TROUBLESHOOTING K3S - LiÃ§Ãµes Aprendidas

**Data:** 25/12/2024
**Projeto:** neo4j-langraph (Sistema de Conhecimento Pessoal)
**Stack:** K3S + Neo4j + LocalAI (llama.cpp) + Gemini Flash 2.5

---

## ğŸ“š ÃNDICE

1. [Resumo dos Problemas](#resumo-dos-problemas)
2. [Problema 1: Imagem do LocalAI nÃ£o existia](#problema-1-imagem-do-localai-nao-existia)
3. [Problema 2: PermissÃµes do PVC no K3S local-path](#problema-2-permissoes-do-pvc-no-k3s-local-path)
4. [Problema 3: Erro de configuraÃ§Ã£o do Neo4j](#problema-3-erro-de-configuraÃ§Ã£o-do-neo4j)
5. [Problema 4: Erro de memÃ³ria do Neo4j](#problema-4-erro-de-memoria-do-neo4j)
6. [Problema 5: ConfiguraÃ§Ã£o contaminada entre serviÃ§os](#problema-5-configuracao-contaminada-entre-servicos)
7. [Problema 6: PV/PVC nÃ£o vinculando](#problema-6-pvpvc-nao-vinculando)
8. [SoluÃ§Ã£o Final](#solucao-final)
9. [Checklist para Futuros Projetos](#checklist-para-futuros-projetos)
10. [ConclusÃ£o](#conclusao)

---

## ğŸ“Š RESUMO DOS PROBLEMAS

| Problema | Status | Dificuldade | Tempo para resolver |
|-----------|---------|--------------|-------------------|
| Imagem LocalAI | âœ… Resolvido | FÃ¡cil | 10 min |
| PermissÃµes PVC | âœ… Resolvido | MÃ©dio | 30 min |
| Config Neo4j | âœ… Resolvido | DifÃ­cil | 1 hora |
| MemÃ³ria Neo4j | âœ… Resolvido | MÃ©dio | 20 min |
| Config contaminada | âœ… Resolvido | DifÃ­cil | 40 min |
| PV/PVC vinculaÃ§Ã£o | âœ… Resolvido | MÃ©dio | 30 min |
| **TOTAL** | **âœ… Resolvidos** | - | **~3 horas** |

---

## ğŸš« PROBLEMA 1: Imagem do LocalAI nÃ£o existia

### Sintoma
```
Error: Failed to pull image "quay.io/go-skynet/local-ai:latest-cublas-cuda12"
Reason: 404 Not Found
Status: ImagePullBackOff
```

### Causa
A tag `latest-cublas-cuda12` NÃƒO existe no repositÃ³rio do LocalAI.

### SoluÃ§Ã£o
```yaml
# ANTES (ERRADO)
image: quay.io/go-skynet/local-ai:latest-cublas-cuda12

# DEPOIS (CORRETO)
image: quay.io/go-skynet/local-ai:v2.18.0-cublas-cuda12
```

### LiÃ§Ãµes Aprendidas
1. âœ… **NUNCA use `:latest` em produÃ§Ã£o**
   - Tags `:latest` podem mudar sem aviso
   - Quebra deployments
   - NÃ£o Ã© reproduzÃ­vel

2. âœ… **Sempre especifique a versÃ£o exata**
   - Use tags semÃ¢nticas: `v2.18.0`
   - Verifique as tags disponÃ­veis antes de usar
   - Teste em ambiente de desenvolvimento primeiro

3. âœ… **Verifique o repositÃ³rio**
   ```bash
   # Verificar tags disponÃ­veis
   curl https://quay.io/api/v1/repository/go-skynet/local-ai/tag/
   ```

---

## ğŸ”’ PROBLEMA 2: PermissÃµes do PVC no K3S local-path

### Sintoma
```
Error: Permission denied
Container: neo4j
Command: su-exec: find: Permission denied
```

### Causa
O K3S local-path provisioner criou PVs em `/mnt/container-data/k3s/storage/` com permissÃµes incorretas. O container Neo4j (roda como usuÃ¡rio 1000) nÃ£o tinha permissÃ£o para escrever no volume.

### SoluÃ§Ã£o 1: PVs DinÃ¢micos (NÃƒO FUNCIONOU)
```yaml
# Tentativa 1 (falhou)
apiVersion: v1
kind: StorageClass
metadata:
  name: local-path
provisioner: rancher.io/local-path
reclaimPolicy: Retain
volumeBindingMode: WaitForFirstConsumer
```

### SoluÃ§Ã£o 2: PVs Manuais (FUNCIONOU) âœ…
```yaml
# Criar PV manual com path especÃ­fico
apiVersion: v1
kind: PersistentVolume
metadata:
  name: neo4j-data-pv
  namespace: neo4j-langraph
spec:
  capacity:
    storage: 5Gi
  accessModes:
    - ReadWriteOnce
  persistentVolumeReclaimPolicy: Retain
  storageClassName: local-path
  local:
    path: /mnt/container-data/projects/neo4j-langraph/neo4j
  nodeAffinity:
    required:
      nodeSelectorTerms:
      - matchExpressions:
        - key: kubernetes.io/hostname
          operator: In
          values:
          - pop-os.local
```

### LiÃ§Ãµes Aprendidas
1. âœ… **PVs manuais = mais controle e previsibilidade**
   - VocÃª sabe exatamente onde os dados estÃ£o armazenados
   - Pode configurar permissÃµes antes do deploy
   - Mais fÃ¡cil de fazer backup

2. âœ… **OrganizaÃ§Ã£o de projetos**
   ```
   /mnt/container-data/
   â”œâ”€â”€ projects/
   â”‚   â”œâ”€â”€ neo4j-langraph/
   â”‚   â”‚   â”œâ”€â”€ neo4j/          (PV do Neo4j)
   â”‚   â”‚   â””â”€â”€ models/         (PV do LocalAI)
   â”‚   â””â”€â”€ fastapi-ddd-dev/
   â””â”€â”€ k3s/                    (Provisioner dinÃ¢mico)
   ```

3. âœ… **Sempre configure `securityContext`**
   ```yaml
   spec:
     securityContext:
       fsGroup: 1000      # Grupo do filesystem
       runAsUser: 1000     # UsuÃ¡rio do container
     containers:
       - name: app
         securityContext:
           runAsNonRoot: true
   ```

4. âœ… **Configure permissÃµes antes do deploy**
   ```bash
   mkdir -p /mnt/container-data/projects/neo4j-langraph/neo4j
   chmod 777 /mnt/container-data/projects/neo4j-langraph/neo4j
   ```

---

## âš™ï¸ PROBLEMA 3: Erro de configuraÃ§Ã£o do Neo4j

### Sintoma
```
Failed to read config: Unrecognized setting.
No declared setting with name: PORT.7687.TCP.PORT
Cleanup the config or disable 'server.config.strict_validation.enabled'
```

### Causa
Neo4j 5.26-community tem validaÃ§Ã£o estrita de configuraÃ§Ã£o. VariÃ¡veis de ambiente de serviÃ§os anteriores (com nomes `neo4j-44`, `neo4j-test`) contaminaram a configuraÃ§Ã£o.

VariÃ¡veis contaminadas:
```
44.SERVICE.PORT.HTTP
44.SERVICE.PORT.BOLT
44.SERVICE.HOST
44.PORT.7687.TCP.PROTO
44.PORT.7687.TCP.PORT
44.PORT.7687.TCP.ADDR
TEST.SERVICE.PORT.HTTP
TEST.SERVICE.PORT.BOLT
TEST.SERVICE.HOST
TEST.PORT.7687.TCP.PROTO
TEST.PORT
```

### SoluÃ§Ã£o 1: Desabilitar validaÃ§Ã£o (NÃƒO FUNCIONOU)
```yaml
# Tentativa 1 (falhou)
env:
  - name: NEO4J_server_config_strict__validation__enabled
    value: "false"
```

### SoluÃ§Ã£o 2: Usar versÃ£o mais estÃ¡vel (FUNCIONOU) âœ…
```yaml
# Usar Neo4j 4.4-community (LTS, mais estÃ¡vel)
image: docker.io/neo4j:4.4-community
```

### LiÃ§Ãµes Aprendidas
1. âœ… **VersÃµes mais novas podem ter bugs**
   - Neo4j 5.x tem problemas com configuraÃ§Ãµes de porta
   - Use versÃµes LTS estÃ¡veis
   - Teste antes de usar em produÃ§Ã£o

2. âœ… **Em K8S, variÃ¡veis podem ser herdadas**
   - ServiÃ§os com nomes similares podem contaminar configs
   - Sempre limpe recursos de teste
   - Use nomes ÃšNICOS e EXPLÃCITOS

3. âœ… **Limpeza total Ã© melhor que tentar corrigir**
   ```bash
   # Se algo der errado, limpe tudo
   kubectl delete namespace [nome] --force --grace-period=0
   kubectl create namespace [nome]
   ```

---

## ğŸ§  PROBLEMA 4: Erro de memÃ³ria do Neo4j

### Sintoma
```
ERROR: Invalid memory configuration - exceeds physical memory
Check configured values for dbms.memory.pagecache.size and dbms.memory.heap.max_size
```

### Causa
Neo4j tentou configurar memÃ³ria automaticamente, mas o valor calculado excedia a memÃ³ria fÃ­sica disponÃ­vel (2GB request vs 2GB limit).

### SoluÃ§Ã£o
```yaml
# Configurar memÃ³ria explicitamente
containers:
  - name: neo4j
    image: docker.io/neo4j:4.4-community
    env:
      - name: NEO4J_AUTH
        value: "neo4j/password"
      - name: NEO4J_dbms_memory_heap_max__size
        value: "512m"
      - name: NEO4J_dbms_memory_pagecache_size
        value: "512m"
    resources:
      requests:
        memory: "1Gi"
        cpu: "500m"
      limits:
        memory: "2Gi"
        cpu: "1000m"
```

### CÃ¡lculo de MemÃ³ria
```
Heap max:      512m
Pagecache:     512m
Total Config:  1GB

Memory Request: 1GB
Memory Limit:   2GB

âœ… Total Config (1GB) < Memory Request (1GB) âœ… OK
âœ… Memory Request (1GB) < Memory Limit (2GB)    âœ… OK
```

### LiÃ§Ãµes Aprendidas
1. âœ… **Sempre configure recursos explicitamente**
   - NÃ£o confie em valores padrÃ£o
   - Heap + Pagecache < Memory Request
   - Memory Request < Memory Limit

2. âœ… **Use requests e limits corretamente**
   ```yaml
   requests:
     memory: "1Gi"    # Garantia mÃ­nima
     cpu: "500m"
   limits:
     memory: "2Gi"    # MÃ¡ximo permitido
     cpu: "1000m"
   ```

3. âœ… **FÃ³rmula segura:**
   ```
   dbms.memory.heap.max_size + dbms.memory.pagecache.size
   â‰¤
   resources.requests.memory

   resources.requests.memory
   â‰¤
   resources.limits.memory
   ```

---

## â˜ ï¸ PROBLEMA 5: ConfiguraÃ§Ã£o contaminada entre serviÃ§os

### Sintoma
```
# Logs do Neo4j mostravam:
WARNING: 44.SERVICE.PORT.HTTP not written to conf file
WARNING: 44.PORT.7687.TCP.PORT not written to conf file
WARNING: TEST.SERVICE.PORT.HTTP not written to conf file
```

### Causa
MÃºltiplos deployments de Neo4j rodando simultaneamente com nomes diferentes:
- `neo4j` (deployment principal)
- `neo4j-test` (deployment de teste)
- `neo4j-44` (deployment de teste)

Kubernetes criou ConfigMaps e Secrets automaticamente que contaminaram a configuraÃ§Ã£o.

### SoluÃ§Ã£o
```bash
# 1. Deletar serviÃ§os de teste
kubectl delete svc/neo4j-test -n neo4j-langraph --force
kubectl delete svc/neo4j-44 -n neo4j-langraph --force

# 2. Deletar deployments de teste
kubectl delete deployment/neo4j-test -n neo4j-langraph --force
kubectl delete deployment/neo4j-44 -n neo4j-langraph --force

# 3. Deletar pods de teste
kubectl delete pod/neo4j-test-xxx -n neo4j-langraph --force
kubectl delete pod/neo4j-44-xxx -n neo4j-langraph --force

# 4. Manter apenas o deployment principal
kubectl get deployment -n neo4j-langraph
# Output: deployment.apps/neo4j âœ…
```

### LiÃ§Ãµes Aprendidas
1. âœ… **Em K8S, recursos de teste poluem o cluster**
   - ConfigMaps
   - Secrets
   - Services
   - Pods

2. âœ… **Deletar recursos de teste imediatamente**
   ```bash
   # Depois de testar, limpe tudo
   kubectl delete namespace [nome] --force --grace-period=0
   ```

3. âœ… **Use nomes Ãºnicos e explÃ­citos**
   ```yaml
   # BOM
   metadata:
     name: neo4j-main  # ExPLÃCITO

   # RUIM
   metadata:
     name: neo4j  # Pode conflitar
   ```

---

## ğŸ”— PROBLEMA 6: PV/PVC nÃ£o vinculando

### Sintoma
```
# PVC estÃ¡ Pending
kubectl get pvc -n neo4j-langraph
NAME                 STATUS    VOLUME
neo4j-data-pvc     Pending    <none>

# Pod estÃ¡ Pending
kubectl get pod -n neo4j-langraph
NAME                       READY   STATUS
neo4j-xxx-xxx             0/1     Pending
# Event: 0/1 nodes are available: persistentvolumeclaim "neo4j-data-pvc" not found
```

### Causa
O PVC nÃ£o encontrou um PV disponÃ­vel. PVs dinÃ¢micos podem nÃ£o vincular automaticamente se houver conflito de nomes ou storage classes.

### SoluÃ§Ã£o
```yaml
# 1. Criar PV manual com nome especÃ­fico
apiVersion: v1
kind: PersistentVolume
metadata:
  name: neo4j-data-pv  # NOME ESPECÃFICO
  namespace: neo4j-langraph
spec:
  capacity:
    storage: 5Gi
  accessModes:
    - ReadWriteOnce
  persistentVolumeReclaimPolicy: Retain
  storageClassName: local-path
  local:
    path: /mnt/container-data/projects/neo4j-langraph/neo4j
  nodeAffinity:
    required:
      nodeSelectorTerms:
      - matchExpressions:
        - key: kubernetes.io/hostname
          operator: In
          values:
          - pop-os.local

---

# 2. Criar PVC vinculado ao PV especÃ­fico
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: neo4j-data-pvc
  namespace: neo4j-langraph
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 5Gi
  storageClassName: local-path
  volumeName: neo4j-data-pv  # VINCULAR AO PV ESPECÃFICO
```

### VerificaÃ§Ã£o
```bash
# 1. Verificar se PV estÃ¡ Available
kubectl get pv
NAME                CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS
neo4j-data-pv      5Gi        RWO            Retain           Available   âœ…

# 2. Verificar se PVC estÃ¡ Bound
kubectl get pvc
NAME                 STATUS    VOLUME
neo4j-data-pvc     Bound      neo4j-data-pv   âœ…

# 3. Verificar se pod estÃ¡ Running
kubectl get pod
NAME                       READY   STATUS
neo4j-xxx-xxx             1/1     Running   âœ…
```

### LiÃ§Ãµes Aprendidas
1. âœ… **PVs dinÃ¢micos podem nÃ£o vincular**
   - Mais imprevisÃ­veis
   - Podem ter conflitos de nomes
   - PVs manuais = mais controle

2. âœ… **Verifique SEMPRE o status**
   ```bash
   # Verificar status de PV
   kubectl get pv -o wide

   # Verificar status de PVC
   kubectl get pvc -o wide

   # Verificar eventos do pod
   kubectl describe pod [pod-name]
   ```

3. âœ… **Use `volumeName` para vinculaÃ§Ã£o explÃ­cita**
   ```yaml
   spec:
     volumeName: neo4j-data-pv  # EXPLÃCITO
   ```

---

## âœ… SOLUÃ‡ÃƒO FINAL

### ConfiguraÃ§Ã£o Funcional

```yaml
# ===== PVC =====
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: neo4j-data-pvc
  namespace: neo4j-langraph
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 5Gi
  storageClassName: local-path
  volumeName: neo4j-data-pv

---
# ===== Deployment =====
apiVersion: apps/v1
kind: Deployment
metadata:
  name: neo4j
  namespace: neo4j-langraph
spec:
  replicas: 1
  selector:
    matchLabels:
      app: neo4j
  template:
    metadata:
      labels:
        app: neo4j
    spec:
      securityContext:
        fsGroup: 1000
        runAsUser: 1000
      containers:
      - name: neo4j
        image: docker.io/neo4j:4.4-community
        ports:
        - containerPort: 7474
          name: http
        - containerPort: 7687
          name: bolt
        env:
        - name: NEO4J_AUTH
          value: "neo4j/password"
        - name: NEO4J_dbms_memory_heap_max__size
          value: "512m"
        - name: NEO4J_dbms_memory_pagecache_size
          value: "512m"
        volumeMounts:
        - name: data
          mountPath: /data
        - name: logs
          mountPath: /logs
        - name: plugins
          mountPath: /plugins
        resources:
          requests:
            memory: "1Gi"
            cpu: "500m"
          limits:
            memory: "2Gi"
            cpu: "1000m"
      volumes:
      - name: data
        persistentVolumeClaim:
          claimName: neo4j-data-pvc
      - name: logs
        emptyDir: {}
      - name: plugins
        emptyDir: {}

---
# ===== Service =====
apiVersion: v1
kind: Service
metadata:
  name: neo4j
  namespace: neo4j-langraph
spec:
  type: NodePort
  selector:
    app: neo4j
  ports:
  - name: http
    port: 7474
    targetPort: 7474
    nodePort: 30474
  - name: bolt
    port: 7687
    targetPort: 7687
    nodePort: 30687
```

### LocalAI (Embeddings com GPU)

```yaml
# ===== Deployment =====
apiVersion: apps/v1
kind: Deployment
metadata:
  name: localai
  namespace: neo4j-langraph
spec:
  replicas: 1
  selector:
    matchLabels:
      app: localai
  template:
    metadata:
      labels:
        app: localai
    spec:
      securityContext:
        fsGroup: 1000
        runAsUser: 1000
      containers:
      - name: localai
        image: quay.io/go-skynet/local-ai:v2.18.0-cublas-cuda12
        ports:
        - containerPort: 8080
          name: http
        envFrom:
        - configMapRef:
            name: localai-config
        env:
        - name: ADDRESS
          value: ":8080"
        volumeMounts:
        - name: models
          mountPath: /models
        resources:
          limits:
            nvidia.com/gpu: 1
          requests:
            memory: "4Gi"
      volumes:
      - name: models
        persistentVolumeClaim:
          claimName: localai-models-pvc

---
# ===== Service =====
apiVersion: v1
kind: Service
metadata:
  name: localai
  namespace: neo4j-langraph
spec:
  type: NodePort
  selector:
    app: localai
  ports:
  - name: http
    port: 8080
    targetPort: 8080
    nodePort: 30808
```

### Acesso aos ServiÃ§os

```bash
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SISTEMA PRONTO!                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸŒ Neo4j Browser (Web):
   URL: http://localhost:30474
   UsuÃ¡rio: neo4j
   Senha: password

ğŸ”Œ Neo4j BOLT (API):
   URL: bolt://localhost:30687
   UsuÃ¡rio: neo4j
   Senha: password

ğŸ¤– LocalAI (API):
   URL: http://localhost:30808
   API Docs: http://localhost:30808/docs
   Models: http://localhost:30808/v1/models
```

### Status dos Recursos

```bash
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STATUS FINAL DO SISTEMA                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ³ PODS:
   âœ… LocalAI:    Running (1/1) - GPU ativa
   âœ… Neo4j:      Running (1/1) - VersÃ£o 4.4

ğŸ® GPU (RTX 4070 - 8GB VRAM):
   Usado: 162MB (2%)
   Livre: 7.6GB (98%)
   Status: DisponÃ­vel para LocalAI

ğŸ’¾ DISCO (/mnt/container-data/):
   Total: 135GB
   Usado: 90GB (70%)
   Livre: 39GB

ğŸ“Š PVs e PVCs:
   âœ… neo4j-data-pv/pvc:   Bound
   âœ… localai-models-pv/pvc:  Bound
   âœ… Caminho: /mnt/container-data/projects/neo4j-langraph/
```

---

## âœ… CHECKLIST PARA FUTUROS PROJETOS

### Antes de criar recursos K8S

- [ ] **Especifique versÃ£o EXATA das imagens**
  ```yaml
  # BOM
  image: quay.io/go-skynet/local-ai:v2.18.0-cublas-cuda12

  # RUIM
  image: quay.io/go-skynet/local-ai:latest
  ```

- [ ] **Crie PVs manuais em `/mnt/container-data/projects/[projeto]/`**
  ```yaml
  local:
    path: /mnt/container-data/projects/nome-projeto/app-data
  ```

- [ ] **Defina `securityContext` com `fsGroup` e `runAsUser`**
  ```yaml
  spec:
    securityContext:
      fsGroup: 1000
      runAsUser: 1000
  ```

- [ ] **Configure `resources.requests` e `resources.limits`**
  ```yaml
  resources:
    requests:
      memory: "1Gi"
      cpu: "500m"
    limits:
      memory: "2Gi"
      cpu: "1000m"
  ```

- [ ] **Use nomes ÃšNICOS e EXPLÃCITOS para serviÃ§os**
  ```yaml
  # BOM
  metadata:
    name: neo4j-main

  # RUIM
  metadata:
    name: neo4j
  ```

### Durante deploy

- [ ] **Verifique `kubectl get pods`**
  ```bash
  # STATUS deve ser "Running"
  kubectl get pods -n [namespace]
  ```

- [ ] **Verifique `kubectl get pvc`**
  ```bash
  # STATUS deve ser "Bound"
  kubectl get pvc -n [namespace]
  ```

- [ ] **Verifique `kubectl logs deployment/[nome]`**
  ```bash
  # Deve estar sem erros
  kubectl logs deployment/[app-name] -n [namespace]
  ```

- [ ] **Deletar recursos de teste imediatamente**
  ```bash
  # Depois de testar, limpe tudo
  kubectl delete namespace [nome] --force --grace-period=0
  kubectl create namespace [nome]
  ```

### VerificaÃ§Ã£o final

- [ ] **Pods Running:**
  ```bash
  kubectl get pods -n [namespace]
  # READY: 1/1, STATUS: Running
  ```

- [ ] **PVCs Bound:**
  ```bash
  kubectl get pvc -n [namespace]
  # STATUS: Bound
  ```

- [ ] **ServiÃ§os acessÃ­veis:**
  ```bash
  kubectl get svc -n [namespace]
  # Verifique NodePorts
  # Teste acesso: curl http://localhost:[nodeport]
  ```

- [ ] **Logs sem erros:**
  ```bash
  kubectl logs deployment/[app-name] -n [namespace] --tail=50
  # Deve estar limpo de erros
  ```

- [ ] **GPU usada (se aplicÃ¡vel):**
  ```bash
  nvidia-smi
  # Verifique se VRAM estÃ¡ sendo usada
  ```

---

## ğŸš€ PROBLEMAS FREQUENTES E SOLUÃ‡Ã•ES

### ImagePullBackOff

**Sintoma:**
```
Status: ImagePullBackOff
```

**Causa:** Imagem nÃ£o existe ou nÃ£o tem permissÃ£o

**SoluÃ§Ã£o:**
```bash
# 1. Verifique se a imagem existe
docker pull [image-name]

# 2. Especifique versÃ£o exata
image: [image]:v1.2.3  # NÃƒO use :latest

# 3. Verifique credenciais (se necessÃ¡rio)
kubectl create secret docker-registry regcred \
  --docker-server=[registry] \
  --docker-username=[username] \
  --docker-password=[password]
```

---

### CrashLoopBackOff

**Sintoma:**
```
Status: CrashLoopBackOff
RESTARTS: 5 (1m ago)
```

**Causa:** AplicaÃ§Ã£o crasha e reinicia

**SoluÃ§Ã£o:**
```bash
# 1. Verifique os logs
kubectl logs [pod-name] -n [namespace] --tail=50

# 2. Verifique os eventos
kubectl describe pod [pod-name] -n [namespace] | grep -A 10 "Events:"

# 3. SoluÃ§Ãµes comuns:
#    - PermissÃµes de arquivo
#    - ConfiguraÃ§Ã£o incorreta
#    - MemÃ³ria insuficiente
#    - DependÃªncias faltando
```

---

### Pending (Pod)

**Sintoma:**
```
Status: Pending
AGE: 5m
```

**Causa:** Recursos nÃ£o disponÃ­veis ou PVC nÃ£o Bound

**SoluÃ§Ã£o:**
```bash
# 1. Verifique eventos
kubectl describe pod [pod-name] -n [namespace] | grep -A 10 "Events:"

# 2. SoluÃ§Ãµes comuns:
#    - PVC nÃ£o estÃ¡ Bound
#    - NÃ³ nÃ£o tem recursos suficientes
#    - NodeAffinity nÃ£o estÃ¡ satisfeita
```

---

### Pending (PVC)

**Sintoma:**
```
NAME                 STATUS    VOLUME
my-pvc              Pending    <none>
```

**Causa:** PVC nÃ£o encontrou PV disponÃ­vel

**SoluÃ§Ã£o:**
```bash
# 1. Verifique PVs disponÃ­veis
kubectl get pv -n [namespace]

# 2. Verifique se PV tem storageClass correta
kubectl get pv [pv-name] -o yaml | grep storageClassName

# 3. Use PV manual com volumeName
kubectl get pvc [pvc-name] -o yaml | grep volumeName
```

---

## ğŸ¯ MELHORES PRÃTICAS

### 1. OrganizaÃ§Ã£o de Projetos

```
/mnt/container-data/
â”œâ”€â”€ projects/
â”‚   â”œâ”€â”€ projeto-1/
â”‚   â”‚   â”œâ”€â”€ app-data/        # PV principal
â”‚   â”‚   â”œâ”€â”€ models/         # PV de modelos
â”‚   â”‚   â””â”€â”€ logs/          # PV de logs
â”‚   â””â”€â”€ projeto-2/
â”‚       â””â”€â”€ app-data/
â””â”€â”€ k3s/                   # Provisioner dinÃ¢mico
```

### 2. Versionamento de Imagens

```yaml
# Sempre use versÃµes especÃ­ficas
image: nginx:1.25.2          # âœ… BOM
image: nginx:stable-alpine    # âœ… BOM
image: nginx:latest          # âŒ RUIM
```

### 3. Gerenciamento de Recursos

```yaml
# Use requests e limits sempre
resources:
  requests:
    memory: "512Mi"
    cpu: "250m"
  limits:
    memory: "1Gi"
    cpu: "500m"
```

### 4. Health Checks

```yaml
# Sempre configure liveness e readiness probes
containers:
  - name: app
    livenessProbe:
      httpGet:
        path: /health
        port: 8080
      initialDelaySeconds: 30
      periodSeconds: 10
    readinessProbe:
      httpGet:
        path: /ready
        port: 8080
      initialDelaySeconds: 5
      periodSeconds: 5
```

### 5. Labels e Annotations

```yaml
# Use labels para organizaÃ§Ã£o
metadata:
  labels:
    app: neo4j
    version: "4.4"
    environment: production
  annotations:
    description: "Neo4j database for knowledge graph"
    owner: "cnmfs"
```

---

## ğŸ“ CONCLUSÃƒO

### O que aprendemos hoje:

1. **âœ… Imagens Docker/K8S**
   - NUNCA use `:latest`
   - Especifique versÃµes semÃ¢nticas
   - Teste antes de usar em produÃ§Ã£o

2. **âœ… Persistent Volumes (PV/PVC)**
   - PVs manuais = mais controle
   - Configure permissÃµes antes do deploy
   - Organize por projeto

3. **âœ… PermissÃµes e SeguranÃ§a**
   - Sempre configure `securityContext`
   - Use `fsGroup` e `runAsUser`
   - Verifique permissÃµes de arquivos

4. **âœ… Gerenciamento de Recursos**
   - Configure memÃ³ria e CPU explicitamente
   - Use requests < limits
   - Heap + Pagecache < Memory Request

5. **âœ… OrganizaÃ§Ã£o K8S**
   - Limpe recursos de teste imediatamente
   - Use nomes Ãºnicos e explÃ­citos
   - Deletar e recriar se algo falhar

6. **âœ… Troubleshooting**
   - Verifique logs: `kubectl logs`
   - Verifique eventos: `kubectl describe`
   - Verifique status: `kubectl get`

### Status Final:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SISTEMA PRONTO E FUNCIONAL!                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

âœ… LocalAI:    Running (1/1) - GPU ativa
âœ… Neo4j:      Running (1/1) - VersÃ£o 4.4
âœ… GPU:         RTX 4070 - 162MB/8GB (2% usado)
âœ… Disco:       39GB livres em /mnt/container-data/
```

### PrÃ³ximos Passos:

1. Testar o sistema
   ```bash
   .venv/bin/python test_gemini_embeddings.py
   ```

2. Ingerir documentos
   ```bash
   .venv/bin/python -m src.cli.knowledge_cli ingest /path/to/docs
   ```

3. Visualizar grafo
   ```bash
   # Abrir no navegador
   http://localhost:30474
   ```

---

**Autor:** CNMFS
**Data:** 25/12/2024
**VersÃ£o:** 1.0.0
