"""Script para testar configuraÃ§Ã£o LLM + Embeddings"""

from src.config import get_llm, get_embeddings, configure_llm, configure_embeddings


def test_default_config():
    """Testa configuraÃ§Ã£o padrÃ£o do .env"""
    print("=" * 70)
    print("ğŸ§ª TESTE 1: ConfiguraÃ§Ã£o PadrÃ£o (.env)")
    print("=" * 70)
    print()

    # LLM padrÃ£o
    print("ğŸ§  Testando LLM (configuraÃ§Ã£o padrÃ£o)...")
    llm = get_llm()
    result = llm.invoke("Responda apenas: OK")
    print(f"âœ… LLM respondeu: {result.content}")
    print()

    # Embeddings padrÃ£o
    print("ğŸ“Š Testando Embeddings (configuraÃ§Ã£o padrÃ£o)...")
    emb = get_embeddings()
    vector = emb.embed_query("teste de embeddings")
    print(f"âœ… Embeddings gerados: {len(vector)} dimensÃµes")
    print()


def test_custom_config():
    """Testa configuraÃ§Ã£o customizada (override endpoint, API key, modelo)"""
    print("=" * 70)
    print("ğŸ§ª TESTE 2: ConfiguraÃ§Ã£o Customizada (Override)")
    print("=" * 70)
    print()

    # LLM customizado
    print("ğŸ§  Testando LLM (configuraÃ§Ã£o customizada)...")
    llm_custom = configure_llm(
        base_url="http://localhost:30808",
        api_key="dummy-key",
        model="llama3.1-8b-instruct"
    )
    result = llm_custom.invoke("Responda apenas: OK (config customizada)")
    print(f"âœ… LLM respondeu: {result.content}")
    print()

    # Embeddings customizados
    print("ğŸ“Š Testando Embeddings (configuraÃ§Ã£o customizada)...")
    emb_custom = configure_embeddings(
        base_url="http://localhost:30808",
        api_key="dummy-key",
        model="bge-small-en-v1.5"
    )
    vector = emb_custom.embed_query("teste de embeddings customizados")
    print(f"âœ… Embeddings gerados: {len(vector)} dimensÃµes")
    print()


def test_engineering_task():
    """Testa tarefa real de engenharia em portuguÃªs"""
    print("=" * 70)
    print("ğŸ§ª TESTE 3: Tarefa Real (Engenharia + PortuguÃªs)")
    print("=" * 70)
    print()

    llm = get_llm()

    prompt = """
    Classifique este arquivo de engenharia de software em portuguÃªs.
    Retorne JSON:
    {{
      "tipo": "projeto | nota | tutorial | outro",
      "linguagem": "Python | JavaScript | outro",
      "stack": ["Django", "FastAPI", etc],
      "descricao": "breve descriÃ§Ã£o"
    }}

    Arquivo: arquitetura_sistema.md
    ConteÃºdo: O sistema usa microserviÃ§os com Django e RabbitMQ.
    Ã‰ um projeto de e-commerce com arquitetura hexagonal.
    """

    print("ğŸ“ Enviando prompt de classificaÃ§Ã£o...")
    print()

    result = llm.invoke(prompt)
    print(f"ğŸ’¬ Resposta do LLM:")
    print(result.content)
    print()


def test_portuguese_quality():
    """Testa qualidade de portuguÃªs"""
    print("=" * 70)
    print("ğŸ§ª TESTE 4: Qualidade de PortuguÃªs")
    print("=" * 70)
    print()

    llm = get_llm()

    prompt = """
    Explique o que Ã© arquitetura hexagonal em engenharia de software.
    Responda em portuguÃªs brasileiro, de forma clara e didÃ¡tica.
    MÃ¡ximo 3 parÃ¡grafos.
    """

    print("ğŸ“ Enviando prompt em portuguÃªs...")
    print()

    result = llm.invoke(prompt)
    print(f"ğŸ’¬ Resposta do LLM:")
    print(result.content)
    print()


def main():
    """Executa todos os testes"""
    print("\n")
    print("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    print("â•‘  ğŸš€ TESTE COMPLETO: LLM + Embeddings (Llama 3.1 8B)            â•‘")
    print("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    print("\n")

    try:
        test_default_config()
        test_custom_config()
        test_engineering_task()
        test_portuguese_quality()

        print("=" * 70)
        print("âœ… TODOS OS TESTES PASSARAM!")
        print("=" * 70)
        print()
        print("ğŸ‰ Sua configuraÃ§Ã£o estÃ¡ pronta:")
        print("   â€¢ LLM: Llama 3.1 8B Instruct (engenharia + portuguÃªs)")
        print("   â€¢ Embeddings: bge-small-en-v1.5 (super rÃ¡pido na GPU)")
        print("   â€¢ API: OpenAI-compatible (LocalAI)")
        print("   â€¢ GPU: RTX 4070 acelerando tudo")
        print()
        return 0

    except Exception as e:
        print(f"\nâŒ ERRO: {e}")
        print("\nVerifique:")
        print("1. LocalAI estÃ¡ rodando: k9s -n neo4j-langraph")
        print("2. Endpoint correto: http://localhost:30808")
        print("3. Modelo estÃ¡ disponÃ­vel no LocalAI")
        print("4. .env estÃ¡ configurado corretamente")
        return 1


if __name__ == '__main__':
    exit(main())
