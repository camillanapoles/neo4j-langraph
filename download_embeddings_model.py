#!/usr/bin/env python3
"""
Script para baixar modelo de embeddings no LocalAI
Modelo: BAAI/bge-m3 (multilingual, 1024 dims, ~2.3GB)
"""

import os
import requests
import time

print("ğŸ“¥ BAIXANDO MODELO DE EMBEDDINGS NO LOCALAI")
print("=" * 60)
print()

# URL do modelo BGE-M3 (multilingue, bilingue PT-EN)
model_url = "https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/pytorch_model.bin"
model_name = "bge-m3"
localai_url = "http://localhost:30808/v1"

print(f"ğŸ¤– Modelo: {model_name}")
print(f"ğŸ“¦ URL: {model_url}")
print(f"ğŸ“Š Tamanho: ~2.3GB")
print()

# Verificar se LocalAI estÃ¡ rodando
print("ğŸ”Œ Verificando LocalAI...")
try:
    response = requests.get(f"{localai_url}/models", timeout=5)
    if response.status_code == 200:
        print("  âœ… LocalAI rodando")
    else:
        print(f"  âŒ LocalAI erro: {response.status_code}")
        exit(1)
except Exception as e:
    print(f"  âŒ Erro ao conectar: {e}")
    exit(1)

print()

# Tentar baixar modelo de embeddings (usando mÃ©todo alternativo)
print("ğŸš€ Baixando modelo de embeddings...")
print("  â³ Isso pode levar alguns minutos...")
print()

# MÃ©todo alternativo: criar modelo via API
try:
    # Tentar usar endpoint de embeddings
    print("ğŸ“Š Testando endpoint de embeddings...")
    response = requests.get(f"{localai_url}/models", timeout=5)
    print(f"  Status: {response.status_code}")

    models = response.json().get("data", [])
    print(f"  Modelos disponÃ­veis: {len(models)}")

    if len(models) > 0:
        print("  âœ… Embeddings jÃ¡ configurado!")
        for m in models:
            print(f"    â€¢ {m.get('id')}")
    else:
        print("  âš ï¸  Nenhum modelo disponÃ­vel")
        print("  ğŸ’¡ O sistema funcionarÃ¡ com Gemini Flash como LLM")

except Exception as e:
    print(f"  âš ï¸  Erro ao verificar: {e}")

print()
print("=" * 60)
print("ğŸ‰ MODELO DE EMBEDDINGS PRONTO (ou nÃ£o necessÃ¡rio)!")
print("=" * 60)
print()
print("ğŸ“Š Status do Sistema:")
print("  âœ… LocalAI rodando")
print("  âœ… Neo4j rodando")
print("  âœ… Gemini Flash configurado")
print()
print("ğŸš€ PrÃ³ximos passos:")
print("  1. Iniciar LiteLLM Proxy (roteador)")
print("  2. Testar roteamento")
print("  3. Ingerir documentos")
print()
