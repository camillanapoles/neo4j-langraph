#!/bin/bash
# Script para iniciar o proxy LiteLLM
# Roteia entre Gemini Flash 2.5 (prim√°rio) e LocalAI (secund√°rio)

echo "ü§ñ INICIANDO LITELLM PROXY..."
echo "========================================"
echo ""

# Carregar vari√°veis de ambiente
source .env.litellm

echo "üìä Configura√ß√£o:"
echo "  ‚Ä¢ Modelo Prim√°rio:  gemini/gemini-2.0-flash-exp"
echo "  ‚Ä¢ Modelo Secund√°rio: localai/llama3.2:3b"
echo "  ‚Ä¢ Estrat√©gia: usage-based-routing"
echo "  ‚Ä¢ Fallback: localai/llama3.2:3b"
echo ""

# Verificar se LocalAI est√° rodando
echo "üîå Verificando LocalAI..."
if curl -s http://localhost:30808/v1/models > /dev/null; then
    echo "  ‚úÖ LocalAI rodando (http://localhost:30808)"
else
    echo "  ‚ùå LocalAI n√£o est√° rodando!"
    echo "  üí° Inicie o LocalAI:"
    echo "     kubectl get pods -n neo4j-langraph"
    exit 1
fi

echo ""

# Iniciar LiteLLM Proxy
echo "üöÄ Iniciando LiteLLM Proxy na porta 4000..."
echo "  URL: http://localhost:4000"
echo "  Health: http://localhost:4000/health"
echo "  Models: http://localhost:4000/v1/models"
echo ""

# Iniciar em background (para n√£o bloquear o terminal)
litellm --config litellm_config.yaml --port 4000 --host 0.0.0.0
